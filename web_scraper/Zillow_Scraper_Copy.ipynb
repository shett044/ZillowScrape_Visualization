{
 "metadata": {
  "name": "",
  "signature": "sha256:bd0a674cd740272444525ef443e81b1e17ba6a3dc822b348b90984bf937f18cc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Scrape 101 - Scrape US Universities\n",
      "\n",
      "You may find US universities from this webpage. \n",
      "http://www.utexas.edu/world/univ/alpha/\n",
      "\n",
      "We will try to extract the url as well as univ names."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use two packages\n",
      "\n",
      "- ```requests```: for making http requets. http://docs.python-requests.org/en/latest/\n",
      "- ```bs4``` (beautifulsoup4): for parsing the content of the page."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bs4 import BeautifulSoup\n",
      "from pylib import utils\n",
      "import json\n",
      "import requests\n",
      "import re\n",
      "from collections import defaultdict\n",
      "from json2csv import Json2Csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# if you run this script from command line \n",
      "# you should run the following to enable unicode printing\n",
      "#utils.enable_utf_print(false)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def init_soup(link):\n",
      "    source = requests.get(link)\n",
      "    soup = BeautifulSoup(source.text)\n",
      "    return soup"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def avg_school_score(m_soup):\n",
      "    i=0.0\n",
      "    count=0\n",
      "    for li in m_soup.find(class_='nearby-schools-list').findAll('li',class_='nearby-school'):\n",
      "        tmp=0\n",
      "        try:\n",
      "            if li.find(class_='gs-rating-number').get_text().isdigit():\n",
      "                tmp=li.find(class_='gs-rating-number').get_text()        \n",
      "        except:\n",
      "            pass\n",
      "        i=i+float(tmp)\n",
      "        count+=1\n",
      "    return i/count;\n",
      "def scrape_links(dic,link):\n",
      "    m_soup=init_soup(link)\n",
      "    dic['school_score']=avg_school_score(m_soup)\n",
      "    for ul in m_soup.findAll('ul',class_='zsg-list_square'):\n",
      "        for li in ul.findAll('li'):\n",
      "            if 'cooling' in li.get_text().lower():\n",
      "                dic['cooling']=1\n",
      "            if 'heating' in li.get_text().lower():\n",
      "                dic['heating']=1   \n",
      "            if 'last sold' in li.get_text().lower():\n",
      "                dic['last_sold']=re.match('.*\\$([\\d,]+)[\\D]*',li.get_text().lower()).group(1) if re.match('.*\\$([\\d,]+)[\\D]*',li.get_text().lower()) is not None else 1\n",
      "            if 'days on zillow' in li.get_text().lower():\n",
      "                dic['doz']=re.match('(\\d+).*',li.get_text().lower()).group(1) if re.match('(\\d+).*',li.get_text().lower()) is not None else 1\n",
      "            if 'deck' in li.get_text().lower():\n",
      "                dic['deck']=1\n",
      "            if 'parking' in li.get_text().lower():\n",
      "                dic['parking']=1 if re.match('.*(\\d)+',li.get_text()) is None else re.match('.*(\\d)+',li.get_text()).group(1)\n",
      "            if 'porch' in li.get_text().lower():\n",
      "                dic['porch']=1\n",
      "            if 'security' in li.get_text().lower():\n",
      "                dic['security']=1\n",
      "            if 'laundry' in li.get_text().lower():\n",
      "                dic['laundry']=1\n",
      "            if 'dishwasher' in li.get_text().lower():\n",
      "                dic['dishwasher']=1\n",
      "            if 'refridg' in li.get_text().lower():\n",
      "                dic['refridg']=1\n",
      "            if '# stories' in li.get_text().lower():\n",
      "                dic['num_stories']=re.match('.*(\\d)+',li.get_text()).group(1)\n",
      "            if 'room count' in li.get_text().lower():\n",
      "                dic['num_rooms']=re.match('.*(\\d)+',li.get_text()).group(1)\n",
      "    return dic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.match('.*\\$(.*)','last sold: sep 2005 for $435,500').group(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "'435,500'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " scrape_links({},'http://www.zillow.com/homedetails/1065-23rd-Ave-SE-Minneapolis-MN-55414/61623538_zpid/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 85,
       "text": [
        "{'cooling': 1,\n",
        " 'deck': 1,\n",
        " 'dishwasher': 1,\n",
        " 'doz': u'18',\n",
        " 'heating': 1,\n",
        " 'last_sold': u'435,500',\n",
        " 'laundry': 1,\n",
        " 'num_rooms': u'2',\n",
        " 'num_stories': u'0',\n",
        " 'parking': u'2',\n",
        " 'porch': 1,\n",
        " 'school_score': 2.3333333333333335}"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getTransitScores(dic,zid):\n",
      "    walk_score_url='http://www.zillow.com/walkscore/GetWalkscore.htm?zpid={}'\n",
      "    source = requests.get(walk_score_url.format(zid))\n",
      "    scores= BeautifulSoup(source.json()['text']).findAll('span',class_='ws-value')\n",
      "    dic['WalkScore']=0\n",
      "    dic['TransitScore']=0\n",
      "    if scores is not None:\n",
      "        dic['WalkScore']=scores[0].text\n",
      "        if len(scores)>1:\n",
      "            dic['TransitScore']=scores[1].text\n",
      "    return dic\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# we use find_all to find all URLs which has a class of \"institution\"\n",
      "\n",
      "properties=[] #This will store all the listing in properties\n",
      "\n",
      "\n",
      "def scrape_data(soup):\n",
      "    '''Scrapes through the web page to fetch below columns related data '''\n",
      "    \n",
      "    col_class=['listing-type','price-large','zestimate','property-address','property-data','property-lot',\\\n",
      "               'property-year','property-broker']#List of classes in Zilllow\n",
      "    \n",
      "    \n",
      "    #Statement to get out if there are no search results spitted from Zillow\n",
      "    if soup.find(id='search-results') is None or soup.find(id='search-results').findAll('article') is None: \n",
      "        return None\n",
      "    \n",
      "    #Each listing is an article -->it is a property box\n",
      "    for record in soup.find(id='search-results').findAll('article'):\n",
      "        #Temp Dictionary to store eeach property data \n",
      "        a_property=defaultdict(int)\n",
      "        \n",
      "        for column in record.find(class_='property-info').findAll('div',class_='column'):\n",
      "            for dts in column.findAll('dt'):\n",
      "                try:\n",
      "                    for classname in dts.get('class'):\n",
      "                        if classname =='listing-type':\n",
      "                            a_property['listing-type']=dts.get_text()\n",
      "                        if classname == 'price-large':\n",
      "                            a_property['price']=dts.get_text().strip(' $').replace(',','')\n",
      "                        if classname =='zestimate':\n",
      "                            tmp=dts.get_text().split(':')[1].strip(' $').replace(',','')\n",
      "                            if 'K' in tmp:\n",
      "                                a_property['zestimate']=float(tmp.strip('K'))*1000\n",
      "                            elif 'M' in tmp:\n",
      "                                a_property['zestimate']=float(tmp.strip('M'))*1000000\n",
      "                            else:\n",
      "                                a_property['zestimate']=tmp\n",
      "                        if classname =='property-address':\n",
      "                            a_property['property-address']=dts.get_text()\n",
      "                            a_property['property-link']='http://www.zillow.com'+dts.find('a').get('href')\n",
      "                            a_property=scrape_links(a_property,a_property['property-link'])\n",
      "                        if classname =='property-data':\n",
      "                            temp=dts.get_text().split()\n",
      "                            i=0\n",
      "\n",
      "                            while i<len(temp):\n",
      "                                if temp[i].isdigit():\n",
      "                                    if temp[i+1].strip(', ') in ['beds','bed']:\n",
      "                                        a_property['bed']=temp[i]\n",
      "                                        i+=1\n",
      "                                    if temp[i+1].strip(', ') in ['bath','baths']: \n",
      "                                        a_property['bath']=temp[i]\n",
      "                                        i+=1\n",
      "                                elif temp[i].find(',') != -1:\n",
      "                                    if temp[i+1].strip() in ['sqft']: \n",
      "                                        a_property['area']=temp[i].replace(',','')\n",
      "                                        i+=1\n",
      "                                i+=1\n",
      "                        if classname =='property-lot':\n",
      "                            lot=dts.get_text().split()\n",
      "\n",
      "                            #acres to sqft\n",
      "                            lot[0]=float(lot[0])*43560 if lot[1] in ['ac'] else lot[0]\n",
      "                            a_property['lotsize']=lot[0]\n",
      "                        if classname =='property-year':\n",
      "                            a_property['year']=re.match('.*([0-9]{4})',dts.get_text()).group(1)\n",
      "                        if classname =='property-broker':\n",
      "                            a_property['broker']=dts.get_text()   \n",
      "                    #GEt transit and walkscore\n",
      "                    link=a_property['property-link']\n",
      "\n",
      "                    zid= re.match('.*\\/(\\d+)_zpid',link).group(1)\n",
      "                    a_property= getTransitScores(a_property,zid)\n",
      "                except:\n",
      "                    pass\n",
      "        properties.append(a_property)\n",
      "    #print properties\n",
      "    return properties\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "###############################################Code Runs here\n",
      "\n",
      "##Change the Link\n",
      "link='http://www.zillow.com/homes/for_sale/IL/fsba,fsbo,fore_lt/pmf,pf_pt/21_rid/44.229457,-81.309814,35.065973,-97.701416_rect/5_zm/{}_p/'\n",
      "pgnum=1\n",
      "while pgnum:\n",
      "    if scrape_data(init_soup(link.format(pgnum))) is not None:\n",
      "        pgnum+=1\n",
      "        print pgnum\n",
      "    else:\n",
      "        break\n",
      "    if pgnum==200:\n",
      "        break\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "key_map = [[\"cooling\",\"cooling\"],[\"deck\",\"deck\"],[\"dishwasher\",\"dishwasher\"],[\"heating\",\"heating\"],[\"last sold\",\"last sold\"],\\\n",
      "           [\"laundry\",\"laundry\"],[\"num_rooms\",\"num_rooms\"],[\"refridg\",\"refridg\"],[\"num_stories\",\"num_stories\"],[\"parking\",\"parking\"],\\\n",
      "           [\"porch\",\"porch\"],[\"school_score\",\"school_score\"],[\"listing-type\",\"listing-type\"],[\"price\",\"price\"],[\"zestimate\",\"zestimate\"],\\\n",
      "           [\"doz\",\"doz\"],[\"property-address\",\"property-address\"],[\"bed\",\"bed\"],[\"bath\",\"bath\"],[\"area\",\"area\"],[\"year\",\"year\"],\\\n",
      "           [\"lotsize\",\"lotsize\"],[\"broker\",\"broker\"],[\"property-link\",\"property-link\"],[\"security\",\"security\"],[\"TransitScore\",\"TransitScore\"],\\\n",
      "           [\"WalkScore\",\"WalkScore\"]]\n",
      "header='\\t'.join([i[0] for i in key_map])\n",
      "def json_to_csv(properties,key_map):\n",
      "    csv_data=[]\n",
      "    for i in properties:\n",
      "        try:\n",
      "            csv_data.append( '\\t'.join([ str(i[j[1]]) if j[1] in i and len(str(i[j[1]]))> 0 else '' for j in key_map]))\n",
      "        except IOError:\n",
      "            pass\n",
      "\n",
      "    return header+'\\n'+'\\n'.join(csv_data)\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "csv_data=json_to_csv(properties,key_map)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Please change to 'a' once runned for first time\n",
      "\n",
      "#PLEASE Look up  you might override data\n",
      "with open('zillow_dataset.txt','a') as f:\n",
      "    f.writelines(csv_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'propeties' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-7-440f68e6dbd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpropeties\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'propeties' is not defined"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}